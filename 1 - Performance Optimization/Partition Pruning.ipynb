{
  "metadata": {
    "kernelspec": {
      "display_name": "Jupyter Notebook",
      "name": "jupyter"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "id": "98eb2244-08d4-4bae-a74e-e98928d4e65b",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": false
      },
      "source": "# Micro partitions\n\nSnowflake stores a table in many small chunks called micro-partitions. \nFor each micro-partition, Snowflake keeps metadata like the MIN and MAX values of each column inside that chunk.\n \n * 50-500 MB of uncompressed data\n * Data stored in columnar format, not rows.\n * Repetition of column range of data can happen, causing ***overlapping***\n  ",
      "execution_count": null
    },
    {
      "id": "411019da-4620-48bd-9a75-aff12c46fc16",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": false
      },
      "source": "## Overlapping micro-partitions\n\nIf we take on one column (example: order_date), each micro-partition has a range:\n\nMicro-partition P1 contain dates from Jan 1 to Jan 10\nMicro-partition P2 contain dates from Jan 11 to Jan 20\n\nThat is 0 data overlapping.\n\nHowever, \nP1: [Jan 01 … Jan 20]\nP2: [Jan 10 … Feb 05]\nP3: [Jan 15 … Jan 25]\n\nJan 15 apperrs in the range of P1, P2 and P3 causing range overlap.\nSo, in case you search for order_date = jan 15. all 3 partitions will be scanned.\n"
    },
    {
      "id": "6d108936-8e7b-4602-8aa9-9b85c7ee5c74",
      "cell_type": "code",
      "metadata": {
        "resultVariableName": "dataframe_4",
        "language": "sql"
      },
      "source": "%%sql -r dataframe_4\nALTER WAREHOUSE COMPUTE_WH SET AUTO_RESUME = TRUE;\nALTER WAREHOUSE COMPUTE_WH RESUME;",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6c087117-d1a8-4d18-b0af-2f124837fd71",
      "cell_type": "code",
      "metadata": {
        "resultVariableName": "dataframe_3",
        "language": "sql"
      },
      "source": "%%sql -r dataframe_3\nselect * from SNOWFLAKE_SAMPLE_DATA.TPCH_SF10.orders limit 10",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "a5be82b2-7e6f-475d-b13f-293e4c05ba07",
      "cell_type": "code",
      "metadata": {
        "language": "sql",
        "resultVariableName": "dataframe_2",
        "name": "Creating a very bad partition table",
        "title": "Creating a very bad partition table"
      },
      "source": "%%sql -r dataframe_2\n\nuse role sysadmin;\ncreate or replace database sf_cert_prep;\n\ncreate or replace table sf_cert_prep.public.t_orders_bad\nas \nselect * from SNOWFLAKE_SAMPLE_DATA.TPCH_SF10.orders order by o_comment  asc ;\n\n--creating a table, forcing to be order by o_comment, even knowing all searches will be on orders.\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "be064fc0-d157-439d-90a6-3a8aae4864d1",
      "cell_type": "code",
      "metadata": {
        "resultVariableName": "dataframe_6",
        "language": "sql"
      },
      "source": "%%sql -r dataframe_6\n\nALTER SESSION SET USE_CACHED_RESULT = FALSE; -- disabling query cache\n-- cleaning warehouse cache\nALTER WAREHOUSE COMPUTE_WH SUSPEND;\nALTER WAREHOUSE COMPUTE_WH RESUME;\n\nselect * from sf_cert_prep.public.t_orders_bad where o_orderdate = '1993-09-08';\nselect --OPERATOR_STATISTICS,\nOPERATOR_STATISTICS:pruning.partitions_scanned::integer as partitions_scanned,\nOPERATOR_STATISTICS:pruning.partitions_total::integer  as partitions_total , \npartitions_scanned/partitions_total as overlap from table(get_query_operator_stats(last_query_id(-1))) where operator_type = 'TableScan';",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3551bdfd-ecfa-462f-b357-c8b87e1bd657",
      "cell_type": "code",
      "metadata": {
        "resultVariableName": "dataframe_10",
        "language": "sql"
      },
      "source": "%%sql -r dataframe_10\ncreate or replace table sf_cert_prep.public.t_orders_good\nas \nselect * from SNOWFLAKE_SAMPLE_DATA.TPCH_SF10.orders order by o_orderdate  asc ;",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "c8288e1f-0e0c-489d-a98e-be3aedf46040",
      "cell_type": "code",
      "metadata": {
        "resultVariableName": "dataframe_11",
        "language": "sql"
      },
      "source": "%%sql -r dataframe_11\n\n\nALTER SESSION SET USE_CACHED_RESULT = FALSE; -- disabling query cache\n-- cleaning warehouse cache\nALTER WAREHOUSE COMPUTE_WH SUSPEND;\nALTER WAREHOUSE COMPUTE_WH RESUME;\n\nselect * from sf_cert_prep.public.t_orders_good where o_orderdate = '1993-09-08';\nselect --OPERATOR_STATISTICS,\nOPERATOR_STATISTICS:pruning.partitions_scanned::integer as partitions_scanned,\nOPERATOR_STATISTICS:pruning.partitions_total::integer  as partitions_total , \npartitions_scanned/partitions_total as overlap from table(get_query_operator_stats(last_query_id(-1))) where operator_type = 'TableScan';",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "b835cab7-4c11-4c2e-afb4-43e25a5f28df",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "## Explanation\n\nUsually we dont have the luxury to rewrite a production table the way we inteded, merge, updates, reloads of the source, will mix up and mess up the way partition were \"optimized\".\nAs alternative for those cases, we can use \"clustering keys\". Clustering keys will create new partitions based on the keys or expressions that we provide.\n* Old paritions will remain unchanged, if not used anymore, they will be marked to be deleted after timetravel / fail safe period\n* New partitons will have priority in the metadata / query plan\n* Re-clustering will not recreate all paritions, only the ones that will benefit the most\n",
      "execution_count": null
    },
    {
      "id": "d0a1b509-0f03-49cc-adf3-bcdfd4741922",
      "cell_type": "code",
      "metadata": {
        "language": "sql",
        "resultVariableName": "dataframe_13"
      },
      "source": "%%sql -r dataframe_13\ncreate or replace table sf_cert_prep.public.t_orders_bad_but_clustered \ncluster by (o_orderdate)\nas \nselect * from SNOWFLAKE_SAMPLE_DATA.TPCH_SF10.orders order by o_comment  asc ;",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "48c26de7-0b62-45f4-a361-1b71b31e466a",
      "cell_type": "code",
      "metadata": {
        "resultVariableName": "dataframe_14",
        "language": "sql"
      },
      "source": "%%sql -r dataframe_14\n\n\nALTER SESSION SET USE_CACHED_RESULT = FALSE; -- disabling query cache\n-- cleaning warehouse cache\nALTER WAREHOUSE COMPUTE_WH SUSPEND;\nALTER WAREHOUSE COMPUTE_WH RESUME;\n\nselect * from sf_cert_prep.public.t_orders_bad_but_clustered where o_orderdate = '1993-09-08';\nselect --OPERATOR_STATISTICS,\nOPERATOR_STATISTICS:pruning.partitions_scanned::integer as partitions_scanned,\nOPERATOR_STATISTICS:pruning.partitions_total::integer  as partitions_total , \npartitions_scanned/partitions_total as overlap from table(get_query_operator_stats(last_query_id(-1))) where operator_type = 'TableScan';",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "c9d87900-e390-4fab-a065-6f04fc3ec536",
      "cell_type": "code",
      "metadata": {
        "resultVariableName": "dataframe_9",
        "language": "sql"
      },
      "source": "%%sql -r dataframe_9\nselect operator_statistics:pruning.partitions_scanned from table(get_query_operator_stats('01c20d9d-0207-99b5-0019-9c5300165a46'))\nwhere operator_type = 'TableScan'\n;",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e71e0692-fbd6-4db0-a22c-aa93229c30a0",
      "cell_type": "code",
      "metadata": {
        "resultVariableName": "dataframe_5",
        "language": "sql"
      },
      "source": "%%sql -r dataframe_5\nselect system$clustering_information('sf_cert_prep.public.t_orders_bad', 'o_orderdate');",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "dcf2608d-f08d-44fc-a19f-bd7d2d5ea699",
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false
      },
      "source": "## Clustering depth"
    },
    {
      "id": "fbc86378-c40c-4fcd-ae9a-a43813789b26",
      "cell_type": "code",
      "metadata": {
        "resultVariableName": "dataframe_1",
        "language": "sql"
      },
      "source": "%%sql -r dataframe_1\n",
      "outputs": [],
      "execution_count": null
    }
  ]
}