{
  "metadata": {
    "kernelspec": {
      "display_name": "Jupyter Notebook",
      "name": "jupyter"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cb0ffd66-38ba-4124-b5fa-976dbe058dd8",
      "metadata": {
        "codeCollapsed": false,
        "collapsed": false
      },
      "source": "# NoSQL - Not only SQL\n\nSnowflake supports the following kinds of data:\n\n- Structured data (AKA \"SQL data\") — such as rows and columns in a table — follows a strict tabular schema.\n\n- Semi-structured data — such as a JSON file or an XML file — has a flexible schema.\n\n- Unstructured data — such as a document, image, or audio file — has no inherent schema.\n\n\n## Unstructured data\n\nSupports the following actions:\n\n- Securely access data files located in cloud storage.\n- Share file access URLs with collaborators and partners.\n- Load file access URLs and other file metadata into Snowflake tables.\n- Process unstructured data.\n- Load unstructured data with Document AI\n\n\n### URL Types\n\n#### Scoped URL\n\n- Permits temporary access to a staged file without granting privileges to the stage.\n- The URL expires when the persisted query result period ends.\n- Give scoped access to data files to specific roles in the same account.\n- Provide access to the files with a view that retrieves scoped URLs. \n- Only roles that have privileges on the view can access the files. \n- Snowflake records information in the query history about who uses a scoped URL to access a file, and when.\n- Ideal for use in custom applications, for providing unstructured data to other accounts through a share, or for downloading and analysis of unstructured data in Snowsight.\n\n#### File URL - Stage File URL \n\n- URL that identifies the database, schema, stage, and file path to a set of files. \n- Does not expire.\n- A role that has sufficient privileges on the stage can access the files.\n- Permanent URL to a file on a stage. \n- To download or access a file, users send the file URL in a GET request to the REST API endpoint along with the authorization token. \n- Ideal for custom applications that require access to unstructured data files.\n\n\n#### Pre-signed URL\n\n- Simple HTTPS URL used to access a file via a web browser.\n- A file is temporarily accessible to users via this URL using a pre-signed access token.\n- The expiration time for the access token is configurable.\n- Used to download or access files without authenticating into Snowflake or passing an authorization token.\n- Pre-signed URLs are open; any user or application can directly access or download the files. \n- Ideal for business intelligence applications or reporting tools that need to display the unstructured file contents.\n",
      "execution_count": null
    },
    {
      "id": "32fd0b61-bc3f-41c0-8ef3-b87a7dd626ef",
      "cell_type": "code",
      "metadata": {
        "resultVariableName": "dataframe_1",
        "language": "sql",
        "name": "Create open_images_stage",
        "title": "Create open_images_stage"
      },
      "source": "%%sql -r dataframe_1\n\nCREATE OR REPLACE STAGE sf_cert_prep.public.my_images_stage\nDIRECTORY = (ENABLE = TRUE)\nENCRYPTION  = (TYPE = 'SNOWFLAKE_SSE')\n  ;\n\nCREATE OR REPLACE STAGE sf_cert_prep.public.my_images_stage2\nDIRECTORY = (ENABLE = TRUE)\nENCRYPTION  = (TYPE = 'SNOWFLAKE_SSE')\n  ;\n\n-- please upload some images in your stage, I tried to automate, but trial accounts dont allow external integration.\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "cecbe9fd-1951-4c01-892d-2774a4bd4a2c",
      "cell_type": "code",
      "metadata": {
        "resultVariableName": "dataframe_13",
        "language": "sql",
        "name": "Manually refresh stage",
        "title": "Manually refresh stage"
      },
      "source": "%%sql -r dataframe_13\nalter stage sf_cert_prep.public.my_images_stage refresh;",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0dac2ae0-3f16-4745-a011-afb232a11c78",
      "cell_type": "code",
      "metadata": {
        "resultVariableName": "dataframe_3",
        "language": "sql",
        "name": "Alter Stage to set auto_refresh",
        "title": "Alter Stage to set auto_refresh"
      },
      "source": "%%sql -r dataframe_3\nAlter stage sf_cert_prep.public.my_images_stage \nset\nDIRECTORY = (ENABLE = TRUE, AUTO_REFRESH=true)",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "77c4ea56-8c86-4a06-a0a4-0d76e7220615",
      "cell_type": "code",
      "metadata": {
        "resultVariableName": "dataframe_7",
        "language": "sql",
        "name": "Query DIRECTORY()",
        "title": "Query DIRECTORY()"
      },
      "source": "%%sql -r dataframe_7\nselect * from \nDIRECTORY (@sf_cert_prep.public.my_images_stage );",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "12076ad3-82e8-48f4-acde-f1351e23f703",
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## Server-side encryption for unstructured data access\n\n### Types of encryption for internal stages\n\n    [ ENCRYPTION = (   TYPE = 'SNOWFLAKE_FULL' | TYPE = 'SNOWFLAKE_SSE' ) ]\n\n#### SNOWFLAKE_FULL\n\n- Client-side ***and*** server-side encryption. \n- The files are encrypted by a client when it uploads them to the internal stage using PUT.\n- Snowflake uses a 128-bit encryption key by default.\n- All files are also automatically encrypted using AES-256 strong encryption on the server side.\n\n#### SNOWFLAKE_SSE\n\n- Server-side encryption only. \n- The files are encrypted when they arrive on the stage by the cloud service where your Snowflake account is hosted.\n\n\nSo at the end, to enable unstructured data access on an internal stage for third party tools (open a downloaded image from stage in your PC for instance) you need to consider using server-side encryption only (SNOWFLAKE_SSE) when creating the stage.\nOtherwise, staged files will be client-side encrypted by default. \nThe encryption keys are owned by Snowflake, and client-side encrypted files are unreadable by users and external tools using pre-signed, file, or scoped URLs.\n\n### Types of encryption for external stage\n\n#### AWS S3\n\n    [ ENCRYPTION = ( [ TYPE = 'AWS_CSE' ] MASTER_KEY = '<string>'\n                       | TYPE = 'AWS_SSE_S3'\n                       | TYPE = 'AWS_SSE_KMS' [ KMS_KEY_ID = '<string>' ]\n                       | TYPE = 'NONE' ) ]\n\n\n#### Google Cloud Storage\n\n\n    [ ENCRYPTION = (   TYPE = 'GCS_SSE_KMS' [ KMS_KEY_ID = '<string>' ]\n                       | TYPE = 'NONE' ) ]\n\n#### Azure Blob\n\n\n    [ ENCRYPTION = (   TYPE = 'AZURE_CSE' MASTER_KEY = '<string>'\n                       | TYPE = 'NONE' ) ]",
      "execution_count": null
    },
    {
      "id": "0d079679-3ed8-4dbe-95b4-4bca95b34ce5",
      "cell_type": "code",
      "metadata": {
        "resultVariableName": "dataframe_5",
        "language": "sql",
        "name": "List Stage Files",
        "title": "List Stage Files"
      },
      "source": "%%sql -r dataframe_5\nlist @sf_cert_prep.public.my_images_stage;",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "b086ab44-381a-4cc9-ac40-d898c299b5aa",
      "cell_type": "code",
      "metadata": {
        "resultVariableName": "dataframe_6",
        "language": "sql",
        "name": "all metadata columns in a directory table",
        "title": "all metadata columns in a directory table"
      },
      "source": "%%sql -r dataframe_6\n\nSELECT *\nFROM DIRECTORY(@sf_cert_prep.public.my_images_stage)  -- exposes RELATIVE_PATH, SIZE, LAST_MODIFIED, FILE_URL, etc.\nORDER BY RELATIVE_PATH;\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "511b90ab-33c5-4105-b04d-62a17acecea9",
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": false,
        "collapsed": false
      },
      "source": "## Directory tables\n\nis an implicit object layered on a stage (not a separate database object) \n\n- Both external and internal stages support directory tables\n\n- Query a list of all the unstructured files on a stage -> size, last modified timestamp, and its Snowflake ***File URL***.\n\n- You can join a directory table with a Snowflake table that contains additional data and metadata about unstructured files.\n\n- Construct a file processing pipeline. You can use a directory table with the Snowpark API or external functions to create a file processing pipeline.\n\n\n### Automated Refresh\n\n#### Internal Stage: Preview feature only for AWS accounts\n\nConditions that triggers the refresh:\n\n- New files in the path are added to the table metadata.\n\n- Changes to files in the path are updated in the table metadata.\n\n- Files no longer in the path are removed from the table metadata.\n\n    CREATE STAGE my_int_stage\n      DIRECTORY = (\n        ENABLE = TRUE\n        AUTO_REFRESH = TRUE\n      );\n\n#### External Stage:\n\nFor the external stages, you need to make sure the cloud storage are also setup.\n\nIn general for all providers, you should do:\n\n1. Create Storage Integration:\n\n    CREATE OR REPLACE STORAGE INTEGRATION s3_int\n      TYPE = EXTERNAL_STAGE\n      STORAGE_PROVIDER = S3\n      ENABLED = TRUE\n      STORAGE_AWS_ROLE_ARN = 'arn:aws:iam::<acct>:role/snowflake-role'\n      STORAGE_ALLOWED_LOCATIONS = ('s3://my-bucket/data/');\n\n    \n2. Create external stage wtih Directory table:\n    \n    CREATE OR REPLACE STAGE my_ext_stage\n      URL = 's3://my-bucket/data/'\n      STORAGE_INTEGRATION = s3_int\n      DIRECTORY = (\n           ENABLE = TRUE\n           AUTO_REFRESH = TRUE\n      );\n\n3. Setup Event notification in the cloud provider\n- S3: SQS Event notifcation\n- GCS: Cloud Pub/Sub\n- Azure: Event Grid\n\n\n##### S3:\n\n![alt](https://docs.snowflake.com/en/_images/storage-integration-s3.png)\n\nhttps://docs.snowflake.com/en/user-guide/data-load-dirtables-auto-s3\n\n##### GCS:\n\n![alt](https://docs.snowflake.com/en/_images/storage-integration-gcs.png)\n\nhttps://docs.snowflake.com/en/user-guide/data-load-dirtables-auto-gcs\n##### Azure Blob:\n\n\nhttps://docs.snowflake.com/en/user-guide/data-load-dirtables-auto-azure\n\n\n\n#### Workaround for \"Automated Refresh\"\n\nAs workaround you can also setup a task that runs periodically to refresh the stage.\n\n\n    CREATE OR REPLACE TASK daily_refresh\n      WAREHOUSE = compute_wh\n      SCHEDULE = 'USING CRON 30 12 * * * UTC' --> once a day at 12:30 UTC\n    AS\n      ALTER STAGE ext_orders REFRESH;\n\n\n",
      "execution_count": null
    },
    {
      "id": "c81c4845-8f32-48a6-a830-172b92b4010c",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": false
      },
      "source": "### BUILD_STAGE_FILE_URL - SQL Function\n\nGenerates a Snowflake file URL to a staged file using the stage name and relative file path as inputs.\n\n#### Arguments:\n- stage_name: \n    - it must be enclosed in single quotes if stage name has spaces.\n\n- relative_file_path:\n    - Path and filename of the file relative to its location in the stage\n\n\n#### Returns     \n\n    https://<account_identifier>/api/files/<db_name>/<schema_name>/<stage_name>/<relative_path>\n\n",
      "execution_count": null
    },
    {
      "id": "05437433-c753-4ffd-8b00-8635a213f4dd",
      "cell_type": "code",
      "metadata": {
        "resultVariableName": "dataframe_9",
        "language": "sql",
        "name": "BUILD_STAGE_FILE_URL",
        "title": "BUILD_STAGE_FILE_URL"
      },
      "source": "%%sql -r dataframe_9\n-- Build a stable file URL (must know relative path)\nSELECT BUILD_STAGE_FILE_URL('@sf_cert_prep.public.my_images_stage', 'my_images_stage/1.jpg') AS file_url;",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "50cc59df-ff1f-4fb1-accb-ccd09440537d",
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "### BUILD_SCOPED_FILE_URL  - SQL Function\n\nGenerates a encoded URL and permits access to a specified file for a limited period of time.\n\n#### Arguments:\n- stage_name: \n    - it must be enclosed in single quotes if stage name has spaces.\n\n- relative_file_path:\n    - Path and filename of the file relative to its location in the stage\n\n- use_privatelink_host_for_business_critical:\n    - Default: True\n    - Specifies whether to add privatelink to the URL for Business Critical accounts\n\n\n#### Returns     \n\n    https://<account_identifier>/api/files/<query_id>/<encoded_file_path>\n",
      "execution_count": null
    },
    {
      "id": "17fc9faf-2c52-41e1-8821-8af13ec8055e",
      "cell_type": "code",
      "metadata": {
        "resultVariableName": "dataframe_10",
        "language": "sql",
        "name": "BUILD_SCOPED_FILE_URL",
        "title": "BUILD_SCOPED_FILE_URL"
      },
      "source": "%%sql -r dataframe_10\nSELECT BUILD_SCOPED_FILE_URL('@sf_cert_prep.public.my_images_stage', '1.jpg') AS scoped_url;",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "91db0bce-4b31-434a-879c-f1354713bf8d",
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "### GET_PRESIGNED_URL  - SQL Function\n\nGenerates a pre-signed URL to a file on a stage using the stage name and relative file path as inputs.\n\n#### Arguments:\n- stage_name: \n    - it must be enclosed in single quotes if stage name has spaces.\n\n- relative_file_path:\n    - Path and filename of the file relative to its location in the stage\n\n- expiration_time:\n    - Default: 3600 - 60 minutes\n    - Length of time (in seconds) after which the short term access token expires\n\n\n#### Returns     \n\n    https://<account_identifier>/api/files/<query_id>/<encoded_file_path>\n",
      "execution_count": null
    },
    {
      "id": "60df30d8-fa9b-4fd3-bdaf-aacf1a04e555",
      "cell_type": "code",
      "metadata": {
        "resultVariableName": "dataframe_11",
        "language": "sql",
        "name": "GET_PRESIGNED_URL",
        "title": "GET_PRESIGNED_URL"
      },
      "source": "-- 10-minute presigned link\nALTER SESSION SET USE_CACHED_RESULT=FALSE;\nUSE \"SF_CERT_PREP\".\"PUBLIC\";\nSELECT GET_PRESIGNED_URL('@sf_cert_prep.public.my_images_stage', '1.jpg', 600) AS presigned_url;",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3d6b4d1a-a6c1-45c9-a18b-99d1765d6e75",
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Case Open\n\nGET_PRESIGNED_URL not working propertly for notebooks running under containers, works normally in Warehouse enviroment.\n\nCase with SF: 01259013",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ed17dfc2-6256-473e-a873-1b4f832463bb",
      "cell_type": "code",
      "metadata": {
        "resultVariableName": "dataframe_21",
        "language": "sql",
        "name": "get the URL of the stage",
        "title": "get the URL of the stage"
      },
      "source": "--Retrieves the URL for an external or internal named stage using the stage name as the input\n\nSELECT GET_STAGE_LOCATION(@\"SF_CERT_PREP\".\"PUBLIC\".MY_IMAGES_STAGE2);",
      "outputs": [],
      "execution_count": null
    }
  ]
}