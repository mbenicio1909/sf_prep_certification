{
  "metadata": {
    "kernelspec": {
      "display_name": "Jupyter Notebook",
      "name": "jupyter"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a85f87e1-eec1-45fb-a083-dd7850e56bca",
      "metadata": {},
      "source": "# Tables\n\n    CREATE [ OR REPLACE ]\n        [ { [ { LOCAL | GLOBAL } ] TEMP | TEMPORARY | VOLATILE | TRANSIENT } ]\n      TABLE [ IF NOT EXISTS ] <table_name>    \n      (\n        -- Column definition \n        -- Additional column definitions           \n        -- Out-of-line constraints        \n      )\n    \n      [ CLUSTER BY ( <expr> [ , <expr> , ... ] ) ]\n      [ ENABLE_SCHEMA_EVOLUTION = { TRUE | FALSE } ]\n      [ DATA_RETENTION_TIME_IN_DAYS = <integer> ]\n      [ MAX_DATA_EXTENSION_TIME_IN_DAYS = <integer> ]\n      [ CHANGE_TRACKING = { TRUE | FALSE } ]\n      [ DEFAULT_DDL_COLLATION = '<collation_specification>' ]\n      [ COPY GRANTS ]\n      [ COPY TAGS ]\n      [ COMMENT = '<string_literal>' ]\n      [ [ WITH ] ROW ACCESS POLICY <policy_name> ON ( <col_name> [ , <col_name> ... ] ) ]\n      [ [ WITH ] AGGREGATION POLICY <policy_name> [ ENTITY KEY ( <col_name> [ , <col_name> ... ] ) ] ]\n      [ [ WITH ] JOIN POLICY <policy_name> [ ALLOWED JOIN KEYS ( <col_name> [ , ... ] ) ] ]\n      [ [ WITH ] STORAGE LIFECYCLE POLICY <policy_name> ON ( <col_name> [ , <col_name> ... ] ) ]\n      [ [ WITH ] TAG ( <tag_name> = '<tag_value>' [ , <tag_name> = '<tag_value>' , ... ] ) ]\n      [ WITH CONTACT ( <purpose> = <contact_name> [ , <purpose> = <contact_name> ... ] ) ]\n\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "ec2b44fc-d6f1-482a-8c29-0aa9fbd28980",
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Permanent\n\n- Default\n- Time Travel (up to 90 days on Enterprise+) \n- 7‑day Fail‑safe for disaster recovery. \n- Recomended for production data\n\n### Cloning: \n- Permanent => Temporary \n- Permanent => Transient \n- Permanent => Permanent",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "9f1564b3-59c0-4cba-96c1-c46b17f8e040",
      "cell_type": "code",
      "metadata": {
        "resultVariableName": "dataframe_1",
        "language": "sql",
        "name": "PERMANENT",
        "title": "PERMANENT"
      },
      "source": "use sf_cert_prep.public;\n\nCREATE OR REPLACE TABLE t_perm (id INT, v STRING);\nINSERT INTO t_perm VALUES (1,'A'),(2,'B');\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "edcbd358-6c7e-4c83-8eba-55b722cbd6e8",
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Transient\n\n- Persist until dropped \n- No Fail‑safe\n- Time Travel 0–1 day\n- Recommended for intermediate/staging data\n\n\n### Cloning: \n- Transient => Temporary \n- Transient => Transient"
    },
    {
      "id": "5e7717ce-4862-4768-9272-9965667a3812",
      "cell_type": "code",
      "metadata": {
        "resultVariableName": "dataframe_2",
        "language": "sql",
        "name": "TRANSIENT",
        "title": "TRANSIENT"
      },
      "source": "use sf_cert_prep.public;\n\n-- Transient (no Fail-safe; Time Travel 0-1 day)\nCREATE OR REPLACE TRANSIENT TABLE t_tran (id INT, v STRING);\nINSERT INTO t_tran VALUES (1,'A'),(2,'B');\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "42ae1909-468d-4303-b459-f825ac9a6a0b",
      "cell_type": "markdown",
      "metadata": {},
      "source": "\n## Temporary\n\n- session‑scoped\n- auto‑dropped at session end\n- no Fail‑safe.\n\n***Important*** you can have a temporary table with the same name as permanent/transient table. The Temporary table will take precedent.\n\nThe data stored in the table contributes to the overall storage charges that Snowflake bills your account. \n\n### Cloning: \n- Temporary => Temporary \n- Temporary => Transient\n"
    },
    {
      "id": "d9861562-615f-43f8-b06c-c34f2c3f6094",
      "cell_type": "code",
      "metadata": {
        "resultVariableName": "dataframe_3",
        "language": "sql",
        "name": "TEMPORARY",
        "title": "TEMPORARY"
      },
      "source": "use sf_cert_prep.public;\n-- Temporary (session-scoped)\nCREATE OR REPLACE TEMPORARY TABLE t_temp (id INT, v STRING);\nINSERT INTO t_temp VALUES (99,'TEMP');\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f384e137-5460-405b-87a1-513835892271",
      "cell_type": "code",
      "metadata": {
        "resultVariableName": "dataframe_4",
        "language": "sql",
        "name": "TEMPORARY TAKING PRECEDENT",
        "title": "TEMPORARY TAKING PRECEDENT"
      },
      "source": "\nuse sf_cert_prep.public;\n\nCREATE OR REPLACE TEMPORARY TABLE t_perm (id INT, v STRING);  -- shadows the permanent\nSELECT * FROM t_perm;  -- returns the temp table\n--DROP TABLE IF EXISTS t_perm; -- drops the temp; permanent still exists\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "67391adf-1ab7-4f64-b747-dec9d34a48a8",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": false
      },
      "source": "## External\n\n- read‑only metadata layer over files in S3/Azure/GCS\n- no DML allowed\n- can be used in query and join operations\n- typically slower than native tables\n- consider a materialized view for speed\n\n\n### File Format:\n- Apache Parquet\n- Apache Avro\n- ORC\n- JSON\n- CSV files\n\n#### Conditions\n- An external table doesn’t inherit FILE_FORMAT options specified in a stage definition when that stage is used for loading data into the table.\n- You must explicitly do so in the external table definition. \n- Snowflake uses defaults for any FILE_FORMAT parameters omitted from the external table definition.\n\n    Default: TYPE = CSV\n\n\n### Column Defintion\n\n#### col_name\nString that specifies the column identifier.\n\n#### col_type\nThe data type must match the result of expr for the column.\n\n#### expr\n\nString that specifies the expression for the column.\n\n- CSV: \n    mycol varchar as (value:c1::varchar)\n- Semi-structured: \n    mycol varchar as (value:\"b\".\"c\"::varchar)\n\n#### METADATA$FILENAME\n\nA pseudocolumn that identifies the name of each staged data file that is included in the external table, including its path in the stage\n\n### REFRESH_ON_CREATE \npecifies whether to automatically refresh the external table metadata one time.\n\n### AUTO_REFRESH \nSpecifies whether Snowflake should enable triggering automatic refreshes of the external table metadata when new or updated data files are available in the named external stage\n\n#### AWS_SNS_TOPIC \nRequired only when configuring AUTO_REFRESH for Amazon S3 stages using Amazon Simple Notification Service (SNS)\n\n\n\n"
    },
    {
      "id": "46c6e10d-8ff6-438b-a57f-1068b04216b6",
      "cell_type": "code",
      "metadata": {
        "language": "sql",
        "resultVariableName": "dataframe_11"
      },
      "source": "-- EXTERNAL - Create external table\nuse sf_cert_prep.public;\n\ndrop  external table if exists Loan_payments_data;\n\nCREATE OR REPLACE FILE FORMAT csv_fmt_loan\n  TYPE = CSV\n  FIELD_DELIMITER = ','\n  FIELD_OPTIONALLY_ENCLOSED_BY = '\"'\n  SKIP_HEADER = 1\n  EMPTY_FIELD_AS_NULL = TRUE\n  NULL_IF = ('', 'NULL');\n\nCREATE OR REPLACE EXTERNAL TABLE Loan_payments_data\n(\n    loan_id         STRING           AS (VALUE:c1::STRING),    \n    loan_status     STRING           AS (VALUE:c2::STRING),\n    principal       NUMBER(18,2)     AS (TRY_TO_DECIMAL(VALUE:c3::STRING, 18, 2)),\n    terms           NUMBER(9,0)      AS (TRY_TO_NUMBER(VALUE:c4::STRING)),\n    effective_date  DATE             AS (TRY_TO_DATE(VALUE:c5::STRING)),\n    due_date        DATE             AS (TRY_TO_DATE(VALUE:c6::STRING)),\n    paid_off_time   TIMESTAMP_NTZ    AS (TRY_TO_TIMESTAMP_NTZ(VALUE:c7::STRING, 'MM/DD/YYYY HH:MI')),\n    past_due_days   NUMBER(9,0)      AS (TRY_TO_NUMBER(VALUE:c8::STRING)),\n    age             NUMBER(9,0)      AS (TRY_TO_NUMBER(VALUE:c9::STRING)),\n    education       STRING           AS (VALUE:c10::STRING),\n    gender          STRING           AS (VALUE:c11::STRING),    \n    file_name       STRING           AS (METADATA$FILENAME),\n    file_row_number NUMBER           AS (METADATA$FILE_ROW_NUMBER)\n)\n\n  WITH LOCATION=@AWS_STAGE\n  PATTERN = '.*Loan_payments_data\\.csv$'\n  FILE_FORMAT= (FORMAT_NAME = SF_CERT_PREP.public.csv_fmt_loan)\n  AUTO_REFRESH=FALSE;\n\n  \nselect * from sf_cert_prep.public.Loan_payments_data;"
    },
    {
      "id": "024648ea-9107-4457-b5e2-780b0bee6bfb",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "\n## Hybrid\n\n***Hybrid tables are currently not available to trial accounts.***\n\nHybrid table is a high performance table focused for transational operation (OLTP‑like access).\n\n - row‑based storage, not columnar as nomral tables, with indexes for low‑latency. \n - PRIMARY KEY required\n - General Available on AWS/Azure only\n - Not allowed as transient/temporary\n\n ### Use cases:\n\n- Metadata for applications and workflows, such as maintaining state for an ingestion workflow that requires high-concurrency updates to a single table from thousands of parallel workers.\n- Lower-latency serving of precomputed aggregates through an API or a user interface.\n- Lightweight transactional applications with relational data models.\n \n### Architecture\n\n- Uses the same Snowflake database service as normal tables.\n- Queries are compiled and optimized in the cloud services layer and executed in the same query engine and virtual warehouses as standard tables\n\n![alt](https://docs.snowflake.com/en/_images/unistore-arch.png)\n\n------------------------------------------------------------------------\n\n\n### Features\n\n\n\n|Feature     | Hybrid                                                        | Standard                 |\n|------------|-----------------------------------------------                |--------------------------|\n|data layout | Row-oriented, with secondary columnar storage                 | Columnar micro-partitions|\n|Locking     | Row-level                                                     | Partition or table       |\n|PRIMARY KEY | Required, enforced                                            | Optional, not enforced   |\n|FOREIGN KEY | Optional, enforced (referential integrity)                    | Optional, not enforced   |\n|UNIQUE      | Optional (except for PRIMARY KEY), enforced                   | Optional, not enforced   |\n|NOT NULL    | Optional (except for PRIMARY KEY), enforced                   | Optional, not enforced   |\n|Indexes     | Supported for performance- updated synchronously on writes    |  search optimization, not enforced   |\n"
    },
    {
      "id": "92f07079-201c-4a2f-9b3e-758488397361",
      "cell_type": "code",
      "metadata": {
        "resultVariableName": "dataframe_13",
        "language": "sql"
      },
      "source": "-- HYBRID - Create external table\n--- Hybrid tables are currently not available to trial accounts.\nCREATE OR REPLACE HYBRID TABLE sf_cert_prep.public.application_log (\n  id NUMBER PRIMARY KEY AUTOINCREMENT,\n  col1 VARCHAR(20),\n  col2 VARCHAR(20) NOT NULL\n  );\n\nINSERT INTO sf_cert_prep.public.application_log (col1, col2) VALUES ('A1', 'B1');\nINSERT INTO sf_cert_prep.public.application_log (col1, col2) VALUES ('A2', 'B2');\nINSERT INTO sf_cert_prep.public.application_log (col1, col2) VALUES ('A3', 'B3');\nINSERT INTO sf_cert_prep.public.application_log (col1, col2) VALUES ('A4', 'B4');\n\n\n\n\nINSERT INTO application_log (col1, col2) VALUES ('A1', 'B1');\nINSERT INTO application_log (col1, col2) VALUES ('A2', 'B2');\nINSERT INTO application_log (col1, col2) VALUES ('A3', 'B3');\nINSERT INTO application_log (col1, col2) VALUES ('A4', 'B4');\n\nSELECT * FROM application_log;\n\nUPDATE application_log SET col2 = 'B3-updated' WHERE id = 3;\n\nDELETE FROM application_log WHERE id = 4;\n\nSELECT * FROM application_log;\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ff2d27f5-c37d-4628-b72a-ea8e05708557",
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Iceberg tables\n\n- data + metadata stored in your cloud storage (via an external volume).\n- No Fail‑safe\n- Snowflake‑managed variant supports full DML\n- external‑catalog variant requires metadata refreshes",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "47ae5180-7b82-49e4-bf05-b0e019491ce5",
      "cell_type": "code",
      "metadata": {
        "resultVariableName": "dataframe_8",
        "language": "sql"
      },
      "source": "-- Pre-req: an EXTERNAL VOLUME to your cloud storage\nCREATE OR REPLACE ICEBERG TABLE ic_orders (\n  order_id INT, amount DOUBLE, created_ts TIMESTAMP_NTZ\n)\nCATALOG = 'SNOWFLAKE'\nEXTERNAL_VOLUME = 'MY_EXT_VOL'\nBASE_LOCATION = 'iceberg/ic_orders';\n\nINSERT INTO ic_orders VALUES (1, 12.34, CURRENT_TIMESTAMP());\nSELECT * FROM ic_orders;",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e7e597e2-9865-467b-923b-992f90563299",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": false
      },
      "source": "## Dynamic\n\n- always‑fresh” tables maintained by Snowflake from a defining query + TARGET_LAG\n- simplify pipelines vs streams/tasks\n- Have important conditions / limitations:\n    - source table must have change tracking enabled\n    - "
    },
    {
      "id": "e34c71cd-d6b7-4f0c-b526-ca9d396b1414",
      "cell_type": "code",
      "metadata": {
        "resultVariableName": "dataframe_7",
        "language": "sql"
      },
      "source": "-- Base table with change tracking + non-zero Time Travel (required for incremental mode)\nCREATE OR REPLACE TABLE raw_events (id NUMBER, ts TIMESTAMP, payload VARIANT);\nALTER TABLE raw_events SET CHANGE_TRACKING = TRUE, DATA_RETENTION_TIME_IN_DAYS = 1;\n\n-- Append some data\nINSERT INTO raw_events SELECT SEQ4(), CURRENT_TIMESTAMP(), OBJECT_CONSTRUCT('k','v') FROM TABLE(GENERATOR(ROWCOUNT=>10));\n\n-- Dynamic table that aggregates counts by day, with 5-min target lag\nCREATE OR REPLACE DYNAMIC TABLE dt_events_daily (\n  day DATE,\n  cnt NUMBER\n)\nTARGET_LAG = '5 minutes'\nWAREHOUSE = COMPUTE_WH\nREFRESH_MODE = INCREMENTAL\nAS\nSELECT DATE_TRUNC('DAY', ts) AS day, COUNT(*) AS cnt\nFROM raw_events\nGROUP BY 1;\n\n-- Query it like a normal table\nSELECT * FROM dt_events_daily ORDER BY day DESC;",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "dcc54b37-4051-420e-afa9-6486f2fd2fee",
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Directory Tables \n- Pseudo-table.\n- Listing of files on a stage\n- Check NoSQL notebook for more details",
      "outputs": [],
      "execution_count": null
    }
  ]
}